{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AGE AND GENDER PREDICTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='New.png' style=\"width:800px;height:500px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Members:-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Nikhil Chawla(18csu140)**\n",
    "- **Palak Dhingra(18csu151)**\n",
    "- **Pranav Goel(18csu158)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mentor:-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Mr. Arpit Yadav**\n",
    "- **Dr. Shaveta Arora**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Description:-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Automatic age and gender classification has become relevant to an increasing amount of applications, particularly since the rise of social platforms and social media. In this project an Age and Gender prediction model is build. The basic idea behind this project was to be able to understand the concepts of deep learning and neural networks. With the advancement of technologies new features are added to our current using applications. One of such fun feature is to detect gender and age of a person who faces the camera at any instance. With the help of this project we tried to create a similar experience.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Description:-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Adience dataset, published in 2014, contains 26,580 photos across 2,284 subjects with a binary gender label and one label from eight different age groups, partitioned into five splits. The key principle of the data set is to capture the images as close to real world conditions as possible, including all variations in appearance, pose, lighting condition and image quality, to name a few.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps invoved:-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Importing libraries and dataset**\n",
    "- **Getting to know the data**\n",
    "- **Data pre-processing**\n",
    "- **Splitting dataset**\n",
    "- **Applying VGG16 model for Gender**\n",
    "- **Applying VGG16 model for Age**\n",
    "- **Model evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Mounting Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wlljaaz3NIBL",
    "outputId": "a724951c-1a27-442f-fe32-f5591fa93ddd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Importing library and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qjfQ_ZDOM8CI"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense, Dropout, LayerNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "um5R4fkdM8CO"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/content/drive/MyDrive/Project/fold_0_data.txt\",sep = \"\\t\" )\n",
    "data1 = pd.read_csv(\"/content/drive/MyDrive/Project/fold_1_data.txt\",sep = \"\\t\")\n",
    "data2 = pd.read_csv(\"/content/drive/MyDrive/Project/fold_2_data.txt\",sep = \"\\t\")\n",
    "data3 = pd.read_csv(\"/content/drive/MyDrive/Project/fold_3_data.txt\",sep = \"\\t\")\n",
    "data4 = pd.read_csv(\"/content/drive/MyDrive/Project/fold_4_data.txt\",sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 536
    },
    "id": "2qCiUDI0M8CP",
    "outputId": "d0319128-911a-4df4-8043-d7d0b4834284"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>original_image</th>\n",
       "      <th>face_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>dx</th>\n",
       "      <th>dy</th>\n",
       "      <th>tilt_ang</th>\n",
       "      <th>fiducial_yaw_angle</th>\n",
       "      <th>fiducial_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30601258@N03</td>\n",
       "      <td>10399646885_67c7d20df9_o.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>(25, 32)</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>414</td>\n",
       "      <td>1086</td>\n",
       "      <td>1383</td>\n",
       "      <td>-115</td>\n",
       "      <td>30</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30601258@N03</td>\n",
       "      <td>10424815813_e94629b1ec_o.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>(25, 32)</td>\n",
       "      <td>m</td>\n",
       "      <td>301</td>\n",
       "      <td>105</td>\n",
       "      <td>640</td>\n",
       "      <td>641</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30601258@N03</td>\n",
       "      <td>10437979845_5985be4b26_o.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>(25, 32)</td>\n",
       "      <td>f</td>\n",
       "      <td>2395</td>\n",
       "      <td>876</td>\n",
       "      <td>771</td>\n",
       "      <td>771</td>\n",
       "      <td>175</td>\n",
       "      <td>-30</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30601258@N03</td>\n",
       "      <td>10437979845_5985be4b26_o.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>(25, 32)</td>\n",
       "      <td>m</td>\n",
       "      <td>752</td>\n",
       "      <td>1255</td>\n",
       "      <td>484</td>\n",
       "      <td>485</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30601258@N03</td>\n",
       "      <td>11816644924_075c3d8d59_o.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>(25, 32)</td>\n",
       "      <td>m</td>\n",
       "      <td>175</td>\n",
       "      <td>80</td>\n",
       "      <td>769</td>\n",
       "      <td>768</td>\n",
       "      <td>-75</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4479</th>\n",
       "      <td>68094148@N04</td>\n",
       "      <td>11373794746_4720ac792a_o.jpg</td>\n",
       "      <td>478</td>\n",
       "      <td>(25, 32)</td>\n",
       "      <td>m</td>\n",
       "      <td>664</td>\n",
       "      <td>0</td>\n",
       "      <td>242</td>\n",
       "      <td>211</td>\n",
       "      <td>-5</td>\n",
       "      <td>-15</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4480</th>\n",
       "      <td>68094148@N04</td>\n",
       "      <td>11355711315_0f5b5da125_o.jpg</td>\n",
       "      <td>477</td>\n",
       "      <td>(25, 32)</td>\n",
       "      <td>f</td>\n",
       "      <td>915</td>\n",
       "      <td>51</td>\n",
       "      <td>109</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4481</th>\n",
       "      <td>10693681@N00</td>\n",
       "      <td>9162730346_b1bf71120a_o.jpg</td>\n",
       "      <td>479</td>\n",
       "      <td>(25, 32)</td>\n",
       "      <td>m</td>\n",
       "      <td>2145</td>\n",
       "      <td>1270</td>\n",
       "      <td>249</td>\n",
       "      <td>249</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4482</th>\n",
       "      <td>113830953@N04</td>\n",
       "      <td>11855529986_dff116e018_o.jpg</td>\n",
       "      <td>480</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2878</td>\n",
       "      <td>1300</td>\n",
       "      <td>306</td>\n",
       "      <td>306</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4483</th>\n",
       "      <td>113830953@N04</td>\n",
       "      <td>11855531166_90b5b3670d_o.jpg</td>\n",
       "      <td>480</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2911</td>\n",
       "      <td>1459</td>\n",
       "      <td>338</td>\n",
       "      <td>338</td>\n",
       "      <td>-95</td>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4484 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            user_id  ... fiducial_score\n",
       "0      30601258@N03  ...             17\n",
       "1      30601258@N03  ...             94\n",
       "2      30601258@N03  ...             74\n",
       "3      30601258@N03  ...             47\n",
       "4      30601258@N03  ...             34\n",
       "...             ...  ...            ...\n",
       "4479   68094148@N04  ...             73\n",
       "4480   68094148@N04  ...             14\n",
       "4481   10693681@N00  ...             25\n",
       "4482  113830953@N04  ...            164\n",
       "4483  113830953@N04  ...            171\n",
       "\n",
       "[4484 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Getting to know the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "alUvQjxeM8CQ",
    "outputId": "d930b1d4-24b3-4a55-ea44-1e9e48d9576b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'original_image', 'face_id', 'age', 'gender', 'x', 'y', 'dx',\n",
       "       'dy', 'tilt_ang', 'fiducial_yaw_angle', 'fiducial_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W7navwZlM8CR",
    "outputId": "f2540bb4-b514-4575-8a2b-6245562ed098"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4484, 12)\n",
      "(19370, 12)\n"
     ]
    }
   ],
   "source": [
    "total_data = pd.concat([data, data1, data2, data3, data4], ignore_index=True)\n",
    "print(data.shape)\n",
    "print(total_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_N6FWqahM8CR",
    "outputId": "d23946e7-9fd3-4615-eedf-947e83ffe632"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19370 entries, 0 to 19369\n",
      "Data columns (total 12 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   user_id             19370 non-null  object\n",
      " 1   original_image      19370 non-null  object\n",
      " 2   face_id             19370 non-null  int64 \n",
      " 3   age                 19370 non-null  object\n",
      " 4   gender              18591 non-null  object\n",
      " 5   x                   19370 non-null  int64 \n",
      " 6   y                   19370 non-null  int64 \n",
      " 7   dx                  19370 non-null  int64 \n",
      " 8   dy                  19370 non-null  int64 \n",
      " 9   tilt_ang            19370 non-null  int64 \n",
      " 10  fiducial_yaw_angle  19370 non-null  int64 \n",
      " 11  fiducial_score      19370 non-null  int64 \n",
      "dtypes: int64(8), object(4)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "total_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "id": "D5TKGcGNM8CS",
    "outputId": "165a8d4d-87f8-461a-ca86-17afd7fd1c63"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>face_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>dx</th>\n",
       "      <th>dy</th>\n",
       "      <th>tilt_ang</th>\n",
       "      <th>fiducial_yaw_angle</th>\n",
       "      <th>fiducial_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4484.000000</td>\n",
       "      <td>4484.000000</td>\n",
       "      <td>4484.000000</td>\n",
       "      <td>4484.000000</td>\n",
       "      <td>4484.000000</td>\n",
       "      <td>4484.000000</td>\n",
       "      <td>4484.000000</td>\n",
       "      <td>4484.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>181.365299</td>\n",
       "      <td>888.913024</td>\n",
       "      <td>664.133586</td>\n",
       "      <td>730.582516</td>\n",
       "      <td>722.762935</td>\n",
       "      <td>-8.220785</td>\n",
       "      <td>3.408787</td>\n",
       "      <td>74.749554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>146.967930</td>\n",
       "      <td>641.385657</td>\n",
       "      <td>460.556195</td>\n",
       "      <td>505.217378</td>\n",
       "      <td>478.369254</td>\n",
       "      <td>84.321376</td>\n",
       "      <td>15.410016</td>\n",
       "      <td>39.049674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>-200.000000</td>\n",
       "      <td>-45.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>364.000000</td>\n",
       "      <td>298.000000</td>\n",
       "      <td>388.000000</td>\n",
       "      <td>389.000000</td>\n",
       "      <td>-85.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>186.000000</td>\n",
       "      <td>793.000000</td>\n",
       "      <td>618.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>613.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>72.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>319.250000</td>\n",
       "      <td>1316.000000</td>\n",
       "      <td>976.500000</td>\n",
       "      <td>854.000000</td>\n",
       "      <td>854.250000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>101.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>480.000000</td>\n",
       "      <td>4983.000000</td>\n",
       "      <td>2752.000000</td>\n",
       "      <td>3264.000000</td>\n",
       "      <td>3225.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>206.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           face_id            x  ...  fiducial_yaw_angle  fiducial_score\n",
       "count  4484.000000  4484.000000  ...         4484.000000     4484.000000\n",
       "mean    181.365299   888.913024  ...            3.408787       74.749554\n",
       "std     146.967930   641.385657  ...           15.410016       39.049674\n",
       "min       1.000000     0.000000  ...          -45.000000        5.000000\n",
       "25%      18.000000   364.000000  ...            0.000000       44.000000\n",
       "50%     186.000000   793.000000  ...            0.000000       72.000000\n",
       "75%     319.250000  1316.000000  ...            0.000000      101.000000\n",
       "max     480.000000  4983.000000  ...           45.000000      206.000000\n",
       "\n",
       "[8 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "id": "tnf7aZtBM8CS",
    "outputId": "e3ec81fd-7866-4bc0-d59a-c53124930d84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f    9372\n",
      "m    8120\n",
      "u    1099\n",
      "Name: gender, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#bar chart\n",
    "gender = ['f','m','u']\n",
    "plt.bar(gender, total_data.gender.value_counts(), color='royalblue',align='center', alpha=0.5)\n",
    "print(total_data.gender.value_counts())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "YxzTlz0OM8CS"
   },
   "outputs": [],
   "source": [
    "df = total_data[['age', 'gender', 'x', 'y', 'dx', 'dy']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "_PMLYE8yM8CT",
    "outputId": "07cd6ba0-094e-4fcd-f419-a74199444508"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>dx</th>\n",
       "      <th>dy</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(25, 32)</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>414</td>\n",
       "      <td>1086</td>\n",
       "      <td>1383</td>\n",
       "      <td>/content/drive/MyDrive/Project/faces/30601258@...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(25, 32)</td>\n",
       "      <td>m</td>\n",
       "      <td>301</td>\n",
       "      <td>105</td>\n",
       "      <td>640</td>\n",
       "      <td>641</td>\n",
       "      <td>/content/drive/MyDrive/Project/faces/30601258@...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(25, 32)</td>\n",
       "      <td>f</td>\n",
       "      <td>2395</td>\n",
       "      <td>876</td>\n",
       "      <td>771</td>\n",
       "      <td>771</td>\n",
       "      <td>/content/drive/MyDrive/Project/faces/30601258@...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(25, 32)</td>\n",
       "      <td>m</td>\n",
       "      <td>752</td>\n",
       "      <td>1255</td>\n",
       "      <td>484</td>\n",
       "      <td>485</td>\n",
       "      <td>/content/drive/MyDrive/Project/faces/30601258@...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(25, 32)</td>\n",
       "      <td>m</td>\n",
       "      <td>175</td>\n",
       "      <td>80</td>\n",
       "      <td>769</td>\n",
       "      <td>768</td>\n",
       "      <td>/content/drive/MyDrive/Project/faces/30601258@...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age gender  ...    dy                                           img_path\n",
       "0  (25, 32)      f  ...  1383  /content/drive/MyDrive/Project/faces/30601258@...\n",
       "1  (25, 32)      m  ...   641  /content/drive/MyDrive/Project/faces/30601258@...\n",
       "2  (25, 32)      f  ...   771  /content/drive/MyDrive/Project/faces/30601258@...\n",
       "3  (25, 32)      m  ...   485  /content/drive/MyDrive/Project/faces/30601258@...\n",
       "4  (25, 32)      m  ...   768  /content/drive/MyDrive/Project/faces/30601258@...\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path = []\n",
    "for row in total_data.iterrows():\n",
    "    path = \"/content/drive/MyDrive/Project/faces/\"+row[1].user_id+\"/coarse_tilt_aligned_face.\"+str(row[1].face_id)+\".\"+row[1].original_image\n",
    "    img_path.append(path)\n",
    "\n",
    "df['img_path'] = img_path\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Zn0xPpfM8CT",
    "outputId": "bde3bce8-1899-464a-f385-5b7a8c529aa6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "#mapping ages\n",
    "age_mapping = [('(0, 2)', '0-2'), ('2', '0-2'), ('3', '0-2'), ('(4, 6)', '4-6'), ('(8, 12)', '8-13'), ('13', '8-13'), ('22', '15-20'), ('(8, 23)','15-20'), ('23', '25-32'), ('(15, 20)', '15-20'), ('(25, 32)', '25-32'), ('(27, 32)', '25-32'), ('32', '25-32'), ('34', '25-32'), ('29', '25-32'), ('(38, 42)', '38-43'), ('35', '38-43'), ('36', '38-43'), ('42', '48-53'), ('45', '38-43'), ('(38, 43)', '38-43'), ('(38, 42)', '38-43'), ('(38, 48)', '48-53'), ('46', '48-53'), ('(48, 53)', '48-53'), ('55', '48-53'), ('56', '48-53'), ('(60, 100)', '60+'), ('57', '60+'), ('58', '60+')]\n",
    "age_mapping_dict = {each[0]: each[1] for each in age_mapping}\n",
    "drop_labels = []\n",
    "for idx, each in enumerate(df.age):\n",
    "    if each == 'None':\n",
    "        drop_labels.append(idx)\n",
    "    else:\n",
    "        df.age.loc[idx] = age_mapping_dict[each]\n",
    "                \n",
    "df = df.drop(labels=drop_labels, axis=0) #droped None values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "P9C_e54KM8CU",
    "outputId": "4851f7b4-d4e8-49aa-e538-03b6fb54f380"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>dx</th>\n",
       "      <th>dy</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25-32</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>414</td>\n",
       "      <td>1086</td>\n",
       "      <td>1383</td>\n",
       "      <td>/content/drive/MyDrive/Project/faces/30601258@...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25-32</td>\n",
       "      <td>m</td>\n",
       "      <td>301</td>\n",
       "      <td>105</td>\n",
       "      <td>640</td>\n",
       "      <td>641</td>\n",
       "      <td>/content/drive/MyDrive/Project/faces/30601258@...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25-32</td>\n",
       "      <td>f</td>\n",
       "      <td>2395</td>\n",
       "      <td>876</td>\n",
       "      <td>771</td>\n",
       "      <td>771</td>\n",
       "      <td>/content/drive/MyDrive/Project/faces/30601258@...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25-32</td>\n",
       "      <td>m</td>\n",
       "      <td>752</td>\n",
       "      <td>1255</td>\n",
       "      <td>484</td>\n",
       "      <td>485</td>\n",
       "      <td>/content/drive/MyDrive/Project/faces/30601258@...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25-32</td>\n",
       "      <td>m</td>\n",
       "      <td>175</td>\n",
       "      <td>80</td>\n",
       "      <td>769</td>\n",
       "      <td>768</td>\n",
       "      <td>/content/drive/MyDrive/Project/faces/30601258@...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age gender  ...    dy                                           img_path\n",
       "0  25-32      f  ...  1383  /content/drive/MyDrive/Project/faces/30601258@...\n",
       "1  25-32      m  ...   641  /content/drive/MyDrive/Project/faces/30601258@...\n",
       "2  25-32      f  ...   771  /content/drive/MyDrive/Project/faces/30601258@...\n",
       "3  25-32      m  ...   485  /content/drive/MyDrive/Project/faces/30601258@...\n",
       "4  25-32      m  ...   768  /content/drive/MyDrive/Project/faces/30601258@...\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jn8yOhC9M8CU",
    "outputId": "093eaaca-09b5-4d95-ee47-f3f9e5f630ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 17452 entries, 0 to 19345\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   age       17452 non-null  object\n",
      " 1   gender    17452 non-null  object\n",
      " 2   x         17452 non-null  int64 \n",
      " 3   y         17452 non-null  int64 \n",
      " 4   dx        17452 non-null  int64 \n",
      " 5   dy        17452 non-null  int64 \n",
      " 6   img_path  17452 non-null  object\n",
      "dtypes: int64(4), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "unbiased_data = df[df.gender != 'u'].copy()\n",
    "unbiased_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "id": "mpUOIJj7M8CU",
    "outputId": "cf5300bd-fcf1-4f7a-df50-a2af1d13b111"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>dx</th>\n",
       "      <th>dy</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>414</td>\n",
       "      <td>1086</td>\n",
       "      <td>1383</td>\n",
       "      <td>/content/drive/MyDrive/Project/faces/30601258@...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>301</td>\n",
       "      <td>105</td>\n",
       "      <td>640</td>\n",
       "      <td>641</td>\n",
       "      <td>/content/drive/MyDrive/Project/faces/30601258@...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2395</td>\n",
       "      <td>876</td>\n",
       "      <td>771</td>\n",
       "      <td>771</td>\n",
       "      <td>/content/drive/MyDrive/Project/faces/30601258@...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>752</td>\n",
       "      <td>1255</td>\n",
       "      <td>484</td>\n",
       "      <td>485</td>\n",
       "      <td>/content/drive/MyDrive/Project/faces/30601258@...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>175</td>\n",
       "      <td>80</td>\n",
       "      <td>769</td>\n",
       "      <td>768</td>\n",
       "      <td>/content/drive/MyDrive/Project/faces/30601258@...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  gender  ...    dy                                           img_path\n",
       "0    4       0  ...  1383  /content/drive/MyDrive/Project/faces/30601258@...\n",
       "1    4       1  ...   641  /content/drive/MyDrive/Project/faces/30601258@...\n",
       "2    4       0  ...   771  /content/drive/MyDrive/Project/faces/30601258@...\n",
       "3    4       1  ...   485  /content/drive/MyDrive/Project/faces/30601258@...\n",
       "4    4       1  ...   768  /content/drive/MyDrive/Project/faces/30601258@...\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_to_label_map = {\n",
    "    'f' : 0,\n",
    "    'm' : 1\n",
    "}\n",
    "\n",
    "age_to_label_map = {\n",
    "    '0-2'  :0,\n",
    "    '4-6'  :1,\n",
    "    '8-13' :2,\n",
    "    '15-20':3,\n",
    "    '25-32':4,\n",
    "    '38-43':5,\n",
    "    '48-53':6,\n",
    "    '60+'  :7\n",
    "}\n",
    "\n",
    "unbiased_data['age'] = unbiased_data['age'].apply(lambda age: age_to_label_map[age])\n",
    "unbiased_data['gender'] = unbiased_data['gender'].apply(lambda g: gender_to_label_map[g])\n",
    "\n",
    "unbiased_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "n--KSmOuM8CV",
    "outputId": "e5d7083e-8ae9-4a4a-cd7b-1ac8e0c94377"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "25-32    5242\n",
       "38-43    2776\n",
       "0-2      2509\n",
       "8-13     2287\n",
       "4-6      2140\n",
       "15-20    1792\n",
       "48-53     909\n",
       "60+       896\n",
       "Name: age, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age = ['25-32','38-43','0-2','8-13','4-6','15-20','48-53','60+']\n",
    "plt.figure(figsize=(15, 5)) \n",
    "plt.bar(age, df.age.value_counts(), alpha=0.8)\n",
    "plt.ylabel('count')\n",
    "plt.show()\n",
    "df.age.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GAzHJ8TnM8CV"
   },
   "source": [
    "## 5. Splitting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hb5B6zxWM8CW",
    "outputId": "a986d95a-0bd8-40a5-969f-822931e4747a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape (13961, 1)\n",
      "Test data shape (3491, 1)\n"
     ]
    }
   ],
   "source": [
    "X = unbiased_data[['img_path']]\n",
    "y = unbiased_data[['gender']]\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print('Train data shape {}'.format(X_train.shape))\n",
    "print('Test data shape {}'.format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "id": "ct0TiKT9M8CW",
    "outputId": "4d26740a-b186-495b-9c0a-a553cfa585f8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17123</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7211</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14902</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15288</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender\n",
       "17123       0\n",
       "7211        1\n",
       "14902       0\n",
       "2083        0\n",
       "15288       1"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "id": "__OcZpWmM8CW",
    "outputId": "a028609f-cc0c-432b-8e4f-a178f44a90bb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16807</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2568</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14275</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender\n",
       "16807       1\n",
       "1355        1\n",
       "2568        1\n",
       "19          1\n",
       "14275       1"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uH1CLDdPM8CW",
    "outputId": "589454ac-4427-4a59-f595-5e52a7a5c223"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images shape (13961, 224, 224, 3)\n",
      "Test images shape (3491, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "train_images = []\n",
    "test_images = []\n",
    "\n",
    "for row in X_train.iterrows():\n",
    "    image = Image.open(row[1].img_path)\n",
    "    image = image.resize((224,224))   \n",
    "    data = np.asarray(image)\n",
    "    train_images.append(data)\n",
    "\n",
    "for row in X_test.iterrows():\n",
    "    image = Image.open(row[1].img_path)\n",
    "    image = image.resize((224, 224))  \n",
    "    data = np.asarray(image)\n",
    "    test_images.append(data)\n",
    "\n",
    "train_images = np.asarray(train_images)\n",
    "test_images = np.asarray(test_images)\n",
    "\n",
    "print('Train images shape {}'.format(train_images.shape))\n",
    "print('Test images shape {}'.format(test_images.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Applying VGG16 model for Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "40is0ppZM8CX"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "base_model = VGG16(input_shape = (224, 224, 3), # Shape of our images\n",
    "include_top = False, # Leave out the last fully connected layer\n",
    "weights = 'imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ev6GYgRYM8CY"
   },
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "gEQ4jsu4M8CY"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "m3TUzRQKM8CY"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "XqjMX-nBM8CY"
   },
   "outputs": [],
   "source": [
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(base_model.output)\n",
    "\n",
    "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "# Add a dropout rate of 0.5\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.models.Model(base_model.input, x)\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0.0001), loss = 'binary_crossentropy',metrics = ['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n3rKg18dM8CZ",
    "outputId": "bf1e15dc-3aa2-41fd-b745-d3926705721b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "349/349 [==============================] - 56s 159ms/step - loss: 3.1394 - acc: 0.7302 - val_loss: 0.6534 - val_acc: 0.8092\n",
      "Epoch 2/5\n",
      "349/349 [==============================] - 58s 167ms/step - loss: 0.3506 - acc: 0.8947 - val_loss: 0.5980 - val_acc: 0.8650\n",
      "Epoch 3/5\n",
      "349/349 [==============================] - 58s 167ms/step - loss: 0.2302 - acc: 0.9358 - val_loss: 0.6275 - val_acc: 0.8808\n",
      "Epoch 4/5\n",
      "349/349 [==============================] - 58s 168ms/step - loss: 0.1168 - acc: 0.9671 - val_loss: 0.7580 - val_acc: 0.8894\n",
      "Epoch 5/5\n",
      "349/349 [==============================] - 59s 169ms/step - loss: 0.0982 - acc: 0.9737 - val_loss: 0.8594 - val_acc: 0.8836\n"
     ]
    }
   ],
   "source": [
    "vgghist = model.fit(train_images, y_train, epochs = 5, validation_split = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q7mew2inuq8X",
    "outputId": "5753c448-c9cd-4745-ab36-b923eb41f8fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'acc']"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "BOVLn80WurJn"
   },
   "outputs": [],
   "source": [
    "losses = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_aL6ohEVurK3",
    "outputId": "d180d75e-3eef-44c2-c19c-0dd3e0a68684"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "[0.7034703493118286, 0.8963047862052917]\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)\n",
    "print(model.evaluate(test_images,y_test,verbose=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "djc5rVjllq6k"
   },
   "source": [
    "## 7. Applying VGG16 model for Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CW6jzVubgO6U",
    "outputId": "7801607c-a589-4d61-ac7a-259023a137e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape (13961, 1)\n",
      "Test data shape (3491, 1)\n"
     ]
    }
   ],
   "source": [
    "X = unbiased_data[['img_path']]\n",
    "y = unbiased_data[['age']]\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print('Train data shape {}'.format(X_train.shape))\n",
    "print('Test data shape {}'.format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "id": "M0mjX5RYgO82",
    "outputId": "eeb5026d-2cb3-46e0-d359-60dc3e319397"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17123</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7211</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14902</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15288</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age\n",
       "17123    6\n",
       "7211     6\n",
       "14902    4\n",
       "2083     5\n",
       "15288    4"
      ]
     },
     "execution_count": 85,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "id": "Iia_Ll4QgO_Z",
    "outputId": "1bdcab7a-7f72-4040-c3aa-19da32c74406"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16807</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2568</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14275</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age\n",
       "16807    1\n",
       "1355     0\n",
       "2568     5\n",
       "19       4\n",
       "14275    4"
      ]
     },
     "execution_count": 86,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K4fCUM7CgPBC",
    "outputId": "82d18791-3823-4f5c-a698-83d332374a88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images shape (13961, 224, 224, 3)\n",
      "Test images shape (3491, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "train_images = []\n",
    "test_images = []\n",
    "\n",
    "for row in X_train.iterrows():\n",
    "    image = Image.open(row[1].img_path)\n",
    "    image = image.resize((224,224))   # Resize the image\n",
    "    data = np.asarray(image)\n",
    "    train_images.append(data)\n",
    "\n",
    "for row in X_test.iterrows():\n",
    "    image = Image.open(row[1].img_path)\n",
    "    image = image.resize((224, 224))  # Resize the image\n",
    "    data = np.asarray(image)\n",
    "    test_images.append(data)\n",
    "\n",
    "train_images = np.asarray(train_images)\n",
    "test_images = np.asarray(test_images)\n",
    "\n",
    "print('Train images shape {}'.format(train_images.shape))\n",
    "print('Test images shape {}'.format(test_images.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "nMw6UtsTgPFV"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "base_model = VGG16(input_shape = (224, 224, 3), # Shape of our images\n",
    "include_top = False, # Leave out the last fully connected layer\n",
    "weights = 'imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "WF_YcDtogPHD"
   },
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "JparW9PpM8Ca"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "V4F6LWiNlRg1"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "5VnP6lxqlRi0"
   },
   "outputs": [],
   "source": [
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(base_model.output)\n",
    "\n",
    "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "# Add a dropout rate of 0.5\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense(8, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.models.Model(base_model.input, x)\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0.0001), loss = 'sparse_categorical_crossentropy',metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xyMXC_u9lRlm",
    "outputId": "d7282df2-d079-4b36-d60a-5c2787f52043"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "349/349 [==============================] - 54s 152ms/step - loss: 7.8352 - acc: 0.2843 - val_loss: 1.6296 - val_acc: 0.4135\n",
      "Epoch 2/5\n",
      "349/349 [==============================] - 56s 159ms/step - loss: 1.5980 - acc: 0.4672 - val_loss: 1.7496 - val_acc: 0.4586\n",
      "Epoch 3/5\n",
      "349/349 [==============================] - 58s 167ms/step - loss: 1.2854 - acc: 0.5832 - val_loss: 1.6636 - val_acc: 0.5231\n",
      "Epoch 4/5\n",
      "349/349 [==============================] - 58s 167ms/step - loss: 1.0186 - acc: 0.6846 - val_loss: 1.7948 - val_acc: 0.5474\n",
      "Epoch 5/5\n",
      "349/349 [==============================] - 59s 168ms/step - loss: 0.8112 - acc: 0.7547 - val_loss: 2.0544 - val_acc: 0.5725\n"
     ]
    }
   ],
   "source": [
    "vgghist = model.fit(train_images, y_train, epochs = 5, validation_split = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ge8GT1dB55nV",
    "outputId": "ec82c644-1a3c-4a43-9d7b-1fc11c35cba2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'acc']"
      ]
     },
     "execution_count": 94,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "UmyLdJMB55pE"
   },
   "outputs": [],
   "source": [
    "losses = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BAi_3gJf55sn",
    "outputId": "6cbc0dcc-9f69-461b-a30e-6de76212751d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "[2.0948915481567383, 0.5691778659820557]\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)\n",
    "print(model.evaluate(test_images,y_test,verbose=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fGJJt8XiM8Ci"
   },
   "source": [
    "## Thank you"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Copy of New_Latest_Final.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
